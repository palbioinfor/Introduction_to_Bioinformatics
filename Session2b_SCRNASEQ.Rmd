---
title: "Single Cell RNA-Seq Analysis"
author: "Pallavi Gaur"
output:
  html_document:
    df_print: paged
Date: May 11, 2022
---
This is a tutorial for the last session of our Mini course in Bioinformatics. In Previous sessions we have learnt the basics of R , how to use librares and basics of bulk RNA-Seq analysis as well. In this session we are going to learn the basic workflow of single cell RNA-Seq using Seurat package as a primary one.

We are using Grubman et al dataset as a practice dataset that has a total of 18468 cells . This study proposes a single-cell atlas of entorhinal cortex from individuals with Alzheimer's disease. To keep the tutorial a bit straightforward and computationally less intensive we will be filterng or downsampling the dataset that will provide us with less number of cells to work with. We will start with the pre -processing and walking through the steps like normalization, scaling , PCA, UMAP projection, we will be clustering the cells , trying to identify the major cell types and looking into the markers and DEG in the clusters.

Let's start with loading the libraries that we need and the Grubamn data seurat object as our input dataset.

### Libraries used
```{r,warning=FALSE}
library(SeuratObject)
library(Seurat)
library(SeuratData)
library(ggplot2)
library(dplyr)
```

### Load the Seurat Object

Give the path to your data and use "load" function to load the R Object. Keeping the verbose "TRUE" we can see the name of the dataset loading. By default, verbose is "FALSE"
```{r}
# load the data
load("/Users/pallavi/Downloads/Introduction_to_Bioinformatics-main/grubman_fin_seurat.Robj",verbose = T)
```


### Check the details of the object by running the name of the dataset
```{r}
 grubman
```

##Standard pre-processing workflow
The steps below encompass the standard pre-processing workflow for scRNA-seq data in Seurat. These represent the selection and filtration of cells based on QC metrics, data normalization and scaling, and the detection of highly variable features
### QC and selecting cells for further analysis
Seurat allows you to easily explore QC metrics and filter cells based on any user-defined criteria. A few QC metrics commonly used by the community include

The number of unique genes detected in each cell.
Low-quality cells or empty droplets will often have very few genes
Cell doublets or multiplets may exhibit an aberrantly high gene count
Similarly, the total number of molecules detected within a cell (correlates strongly with unique genes)
The percentage of reads that map to the mitochondrial genome
Low-quality / dying cells often exhibit extensive mitochondrial contamination
We calculate mitochondrial QC metrics with the PercentageFeatureSet() function, which calculates the percentage of counts originating from a set of features
We use the set of all genes starting with MT- as a set of mitochondrial genes


```{r}
# The [[ ]] operator can add columns to object metadata
grubman[["percent.mt"]] <- PercentageFeatureSet(grubman, pattern = "^MT-")
```


### Visualize QC metrics violin plots
Here we visualize QC metrics and use these to filter cells.

We filter cells that have unique feature counts over 1000 or less than 600
We filter cells that have >5% mitochondrial counts

```{r}
VlnPlot(grubman, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
```

FeatureScatter is typically used to visualize feature-feature relationships, but can be used 0for anything calculated by the object, i.e. columns in object metadata, PC scores etc.

```{r}
plot1 <- FeatureScatter(grubman, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(grubman, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
plot1 + plot2
```

#### Filtering the data
```{r}
#subset(grubman, downsample = 4000)
grubman_filt <- subset(grubman, subset = nFeature_RNA >600 &  nFeature_RNA < 1000 & percent.mt < 5)
grubman_filt
```

### Normalizing the data
After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. Normalized values are stored in dataname[["RNA"]]@data.

Note- The default parameters do not need to be specified and the function can be run without specifying them (unless we want to change the values of the default parameters)

```{r}
grubman_norm <- NormalizeData(grubman_filt, normalization.method = "LogNormalize", scale.factor = 10000)
grubman_norm <- NormalizeData(grubman_filt)
```
### Identification of highly variable features (feature selection)
We next calculate a subset of features that exhibit high cell-to-cell variation in the dataset (i.e, they are highly expressed in some cells, and lowly expressed in others). It has been found that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.

The function FindVariableFeatures() directly models the mean-variance relationship inherent in single-cell data taking 2,000 features by default per dataset. These will be used in downstream analysis, like PCA.


```{r}
grubman_norm <- FindVariableFeatures(grubman_norm, selection.method = "vst", nfeatures = 2000)

# Identify the 10 most highly variable genes
top20 <- head(VariableFeatures(grubman_norm), 20)
# plot variable features with and without labels
plot1 <- VariableFeaturePlot(grubman_norm)
plot1 <- LabelPoints(plot = plot1, points = top20, repel = TRUE)
plot1
```

### Scaling the data
Next, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. 
The ScaleData() function:
Shifts the expression of each gene, so that the mean expression across cells is 0
Scales the expression of each gene, so that the variance across cells is 1
This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate
The results of this are stored in dataname[["RNA"]]@scale.data

Scaling is an essential step in the Seurat workflow, but only on genes that will be used as input to PCA. Therefore, the default in ScaleData() is only to perform scaling on the previously identified variable features (2,000 by default).

Your PCA and clustering results will be unaffected. However, Seurat heatmaps require genes in the heatmap to be scaled, to make sure highly-expressed genes don’t dominate the heatmap. To make sure we don’t leave any genes out of the heatmap later, we are scaling all genes in this tutorial.

```{r}
all.genes <- rownames(grubman_norm)
grubman_scale <- ScaleData(grubman_norm, features = all.genes)
#grubman_scale <- ScaleData(grubman_norm)
grubman_scale
```

The ScaleData() function to remove unwanted sources of variation from a single-cell dataset. For example, we could ‘regress out’ heterogeneity associated with mitochondrial contamination. 

```{r}
#grubman_scale <- ScaleData(pbmc, vars.to.regress = "percent.mt")
```

###Perform linear dimensional reduction
Next we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset.
```{r}

grubman_pca <- RunPCA(grubman_scale,features = VariableFeatures(object = grubman_norm))
# Examine and visualize PCA results a few different ways
#print(pbmc[["pca"]], dims = 1:5, nfeatures = 5)
```
Seurat provides several useful ways of visualizing both cells and features that define the PCA, including VizDimReduction(), DimPlot(), and DimHeatmap()

```{r}
DimHeatmap(grubman_pca, dims = 1, cells = 500, balanced = TRUE)
```

### Determine the ‘dimensionality’ of the dataset 
‘Elbow plot’: a ranking of principle components based on the percentage of variance explained by each one (ElbowPlot() function). In this example, we can observe an ‘elbow’ around PC15, suggesting that the majority of true signal is captured in the first 15 PCs.

```{r}
ElbowPlot(grubman_pca)
```

### Cluster the cells
Seurat applies a graph-based clustering approach, building upon initial strategies in (Macosko et al). Importantly, the distance metric which drives the clustering analysis (based on previously identified PCs) remains the same. Briefly, these methods embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’.

As in PhenoGraph, we first construct a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset (first 15 PCs).

To cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimizing the standard modularity function. The FindClusters() function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets. The clusters can be found using the Idents() function.
```{r}
grubman_pca <- FindNeighbors(grubman_pca, dims = 1:15)
grubman_pca <- FindClusters(grubman_pca, resolution = 0.5)
#grubman_pca_0.2 <- FindClusters(grubman_pca, resolution = 0.2)
# Look at cluster IDs of the first 5 cells
head(Idents(grubman_pca), 5)
```

### Run non-linear dimensional reduction (UMAP/tSNE)
Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis.

```{r}
# If you haven't installed UMAP, you can do so via reticulate::py_install(packages =
# 'umap-learn')
grubman_umap <- RunUMAP(grubman_pca, dims = 1:15)
#grubman_umap_0.2 <- RunUMAP(grubman_pca_0.2, dims = 1:15)
# note that you can set `label = TRUE` or use the LabelClusters function to help label
# individual clusters
DimPlot(grubman_umap, reduction = "umap",label = T)
#DimPlot(grubman_umap_0.2, reduction = "umap")
```

```{r}
# Excitatory neurons (SLC17A6+, SLC17A7+)
# Inhibitory neurons (GAD2+, SLC32A1+)
# Astrocytes (AQP4+, FGFR3+, ALDH1L1+)
# Oligodendrocytes (MOG+)
# Oligodendrocyte precursor cells (PDGFRA+)
# Microglia (AIF1+, C1QA+)
# Endothelial cells (CLDN5+)
# Pericytes (RGS5+)
features<-c("SLC17A6","SLC17A7","GAD2","SLC32A1",
            "AQP4","FGFR3", "ALDH1L1","MOG","PDGFRA",
            "AIF1","C1QA","CLDN5","RGS5")

DotPlot(grubman_umap,
            features  = features,
            cols = c("#70e1f5","#B00B1E"), dot.scale = 8,scale.max = 100,scale.min = 0)+
theme(axis.text.x = element_text(size = 12),
      axis.text.y = element_text(size = 12))+RotatedAxis()

```

```{r fig.width = 19, fig.height=14}
features_<-c("SLC17A7","GAD2",
            "AQP4","MOG","PDGFRA",
            "AIF1","CLDN5","RGS5")
FeaturePlot(grubman_umap, 
            reduction = "umap", 
            features =features_, 
            order = TRUE,
            min.cutoff = 'q10', 
            label = TRUE)
```


```{r}

new.cluster.ids <- c("Oligodendrocytes", "Oligodendrocytes", "OPCs", "Astrocytes", "Astrocytes", "Excitatory neurons","Inhibitory neurons","Microglia","Inhibitory neurons","Astrocytes","UNK","Endothelial","Pericytes", "Astrocytes")
names(new.cluster.ids) <- levels(grubman_umap)
grubman_umap_label <- RenameIdents(grubman_umap, new.cluster.ids)
DimPlot(grubman_umap_label, reduction = "umap", label = TRUE, pt.size = 0.5) + NoLegend()
```

#### Finding differentially expressed features (cluster biomarkers)
Seurat can help you find markers that define clusters via differential expression. By default, it identifies positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers() automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.

The min.pct argument requires a feature to be detected at a minimum percentage in either of the two groups of cells, and the thresh.test argument requires a feature to be differentially expressed (on average) by some amount between the two groups. You can set both of these to 0, but with a dramatic increase in time - since this will test a large number of features that are unlikely to be highly discriminatory. As another option to speed up these computations, max.cells.per.ident can be set. This will downsample each identity class to have no more cells than whatever this is set to. While there is generally going to be a loss in power, the speed increases can be significant and the most highly differentially expressed features will likely still rise to the top.

#### FindAllMarkers
Finds markers (differentially expressed genes) for each of the identity classes in a dataset.
Seurat has several tests for differential expression which can be set with the test.use parameter. For example, the ROC test returns the ‘classification power’ for any individual marker (ranging from 0 - random, to 1 - perfect).

```{r}
# find markers for every cluster compared to all remaining cells, report only the positive
# ones
grubman.findallmarkers <- FindAllMarkers(grubman_umap, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)
grubman.findallmarkers %>%
    group_by(cluster) %>%
    slice_max(n = 2, order_by = avg_log2FC)
```

### Visulaization
Seurat provides several tools for visualizing marker expression. VlnPlot() (shows expression probability distributions across clusters), and FeaturePlot() (visualizes feature expression on a tSNE or PCA plot) are our most commonly used visualizations. We also suggest exploring RidgePlot(), CellScatter(), and DotPlot() as additional methods to view your dataset.
#### Violin Plot
```{r}
VlnPlot(grubman_umap, features = c("SLC5A11", "GFAP"))
# you can plot raw counts as well
#VlnPlot(grubman_umap, features = c("SLC5A11", "GFAP"), slot = "counts", log = TRUE)
```

#### Heatmap
```{r}
grubman.findallmarkers %>%
    group_by(cluster) %>%
    top_n(n = 5, wt = avg_log2FC) -> top5
DoHeatmap(grubman_umap, features = top5$gene) + NoLegend()
```

#### FindMarkers
Finds markers (differentially expressed genes) for identity classes
```{r}
# find all markers of cluster 10
cluster10.markers <- FindMarkers(grubman_umap, ident.1 = 10, min.pct = 0.25)
head(cluster10.markers, n = 5)
```

Find all markers distinguishing cluster 10 from clusters2
```{r}

cluster10.markers <- FindMarkers(grubman_umap, ident.1 = 10, ident.2 = c(), min.pct = 0.25)
head(cluster10.markers, n = 5)
```



